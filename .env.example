# ============================================================================
# FileIntel Environment Configuration
# ============================================================================
# All settings have sensible defaults in config/default.yaml
# Only override the values you need to change
# ============================================================================

# ----------------------------------------------------------------------------
# Database Configuration (PostgreSQL)
# ----------------------------------------------------------------------------
DB_USER=user
DB_PASSWORD=password
DB_HOST=localhost
DB_PORT=5432
DB_NAME=fileintel

# Legacy database variables (deprecated, use DB_* instead)
POSTGRES_USER=user
POSTGRES_PASSWORD=password
POSTGRES_DB=fileintel

# ----------------------------------------------------------------------------
# Storage Configuration
# ----------------------------------------------------------------------------
# STORAGE_TYPE=postgres
# STORAGE_CACHE_TTL=3600
# STORAGE_REDIS_HOST=localhost
# STORAGE_POOL_SIZE=50
# STORAGE_MAX_OVERFLOW=50
# STORAGE_POOL_TIMEOUT=300

# ----------------------------------------------------------------------------
# Redis Configuration (for caching)
# ----------------------------------------------------------------------------
# REDIS_HOST=redis
# REDIS_PORT=6379
# REDIS_DB=0

# ----------------------------------------------------------------------------
# Logging Configuration
# ----------------------------------------------------------------------------
# LOG_LEVEL=WARNING  # Options: DEBUG, INFO, WARNING, ERROR
# Recommended: WARNING for production, INFO for development, DEBUG for troubleshooting

# ----------------------------------------------------------------------------
# LLM Provider Configuration
# ----------------------------------------------------------------------------
# LLM_PROVIDER=openai  # Options: openai, anthropic
# LLM_MODEL=gemma3-12b-awq
# LLM_CONTEXT_LENGTH=128000
# LLM_TEMPERATURE=0.1
# LLM_RATE_LIMIT=999
# LLM_TASK_TIMEOUT=7200
# LLM_TASK_HARD_LIMIT=7200

# Circuit breaker settings
# LLM_CIRCUIT_BREAKER_THRESHOLD=5
# LLM_CIRCUIT_BREAKER_WINDOW=60
# LLM_CIRCUIT_BREAKER_DURATION=30

# ----------------------------------------------------------------------------
# OpenAI Configuration
# ----------------------------------------------------------------------------
OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_BASE_URL=http://192.168.0.247:9003/v1
# OPENAI_EMBEDDING_BASE_URL=http://192.168.0.136:9003/v1
# OPENAI_RATE_LIMIT=999

# ----------------------------------------------------------------------------
# Anthropic Configuration
# ----------------------------------------------------------------------------
# ANTHROPIC_API_KEY=your_anthropic_api_key_here
# ANTHROPIC_RATE_LIMIT=15

# ----------------------------------------------------------------------------
# RAG Configuration
# ----------------------------------------------------------------------------
# RAG_STRATEGY=separate  # Options: merge, separate
# RAG_EMBEDDING_PROVIDER=openai
# RAG_EMBEDDING_MODEL=bge-large-en
# RAG_EMBEDDING_MAX_TOKENS=450
# RAG_ENABLE_TWO_TIER_CHUNKING=false

# RAG Chunking
# RAG_CHUNK_SIZE=800
# RAG_CHUNK_OVERLAP=80
# RAG_TARGET_SENTENCES=3
# RAG_OVERLAP_SENTENCES=1

# RAG Async Processing
# RAG_ASYNC_ENABLED=true
# RAG_ASYNC_BATCH_SIZE=4
# RAG_ASYNC_MAX_CONCURRENT=25
# RAG_ASYNC_BATCH_TIMEOUT=300
# RAG_ASYNC_FALLBACK=true

# RAG Query Classification (LLM-based intelligent routing)
# RAG_CLASSIFICATION_METHOD=hybrid  # Options: llm (LLM only), keyword (keywords only), hybrid (LLM + keyword fallback)
# RAG_CLASSIFICATION_MODEL=gemma3-4B  # Use small/fast model for classification
# RAG_CLASSIFICATION_TEMPERATURE=0.0  # 0.0 = deterministic classification
# RAG_CLASSIFICATION_MAX_TOKENS=150
# RAG_CLASSIFICATION_TIMEOUT=5  # Seconds before falling back to keywords
# RAG_CLASSIFICATION_CACHE_ENABLED=true  # Cache classification results to reduce costs
# RAG_CLASSIFICATION_CACHE_TTL=3600  # Cache for 1 hour

# RAG Result Reranking (improves relevance, adds 50-200ms latency)
# RAG_RERANKING_ENABLED=false  # Enable to improve result quality
# RAG_RERANKING_MODEL=BAAI/bge-reranker-v2-m3  # Multilingual reranker model
# RAG_RERANKING_MODEL_TYPE=normal  # Options: normal, llm, layerwise
# RAG_RERANKING_USE_FP16=true  # Faster inference with FP16
# RAG_RERANKING_INITIAL_K=20  # Retrieve more chunks initially
# RAG_RERANKING_FINAL_K=5  # Return top K after reranking
# RAG_RERANK_VECTOR=true  # Rerank vector search results
# RAG_RERANK_GRAPH=true  # Rerank GraphRAG results
# RAG_RERANK_HYBRID=true  # Rerank hybrid query results
# RAG_RERANKING_DEVICE=auto  # Options: auto, cuda, cpu
# RAG_RERANKING_BATCH_SIZE=32  # Batch size for reranking
# RAG_RERANKING_NORMALIZE=true  # Normalize scores to 0-1
# RAG_RERANKING_MIN_SCORE=null  # Filter results below this score (e.g., 0.3)

# ----------------------------------------------------------------------------
# GraphRAG Configuration
# ----------------------------------------------------------------------------
# GRAPHRAG_LLM_MODEL=gemma3-12b-awq
# GRAPHRAG_EMBEDDING_MODEL=bge-large-en
# GRAPHRAG_COMMUNITY_LEVELS=3
# GRAPHRAG_MAX_TOKENS=12000
# GRAPHRAG_INDEX_PATH=./graphrag_indices

# GraphRAG Cache
# GRAPHRAG_CACHE_ENABLED=true
# GRAPHRAG_CACHE_TTL=3600
# GRAPHRAG_CACHE_MAX_SIZE_MB=500

# GraphRAG Query Routing
# GRAPHRAG_CLASSIFICATION_MODEL=gemma3-12b-awq

# GraphRAG Async Processing
# GRAPHRAG_ASYNC_ENABLED=true
# GRAPHRAG_ASYNC_BATCH_SIZE=4
# GRAPHRAG_ASYNC_MAX_CONCURRENT=50
# GRAPHRAG_ASYNC_BATCH_TIMEOUT=300
# GRAPHRAG_ASYNC_FALLBACK=true
# GRAPHRAG_EMBEDDING_BATCH_MAX_TOKENS=450

# ----------------------------------------------------------------------------
# Document Processing Configuration
# ----------------------------------------------------------------------------
# DOC_CHUNK_SIZE=800
# DOC_CHUNK_OVERLAP=80
# DOC_MAX_FILE_SIZE=300MB
# DOC_PRIMARY_PDF_PROCESSOR=mineru  # Options: mineru, traditional
# DOC_USE_TYPE_AWARE_CHUNKING=true

# ----------------------------------------------------------------------------
# MinerU OCR Configuration
# ----------------------------------------------------------------------------
# MINERU_API_TYPE=selfhosted  # Options: selfhosted, commercial
# MINERU_BASE_URL=http://192.168.0.136:8000
# MINERU_TIMEOUT=null
# MINERU_ENABLE_FORMULA=false
# MINERU_ENABLE_TABLE=true
# MINERU_LANGUAGE=en
# MINERU_MODEL_VERSION=pipeline  # Options: pipeline, vlm
# MINERU_SAVE_OUTPUTS=true
# MINERU_OUTPUT_DIR=/home/appuser/app/mineru_outputs
# MINERU_USE_ELEMENT_LEVEL_TYPES=true
# MINERU_ENABLE_ELEMENT_FILTERING=true

# MinerU Commercial API (only if api_type=commercial)
# MINERU_API_TOKEN=your_token_here
# MINERU_POLL_INTERVAL=10
# MINERU_MAX_RETRIES=3
# MINERU_SHARED_FOLDER_PATH=/shared/uploads
# MINERU_SHARED_FOLDER_URL_PREFIX=file:///shared/uploads

# ----------------------------------------------------------------------------
# Output Configuration
# ----------------------------------------------------------------------------
# OUTPUT_DEFAULT_FORMAT=json
# OUTPUT_DIRECTORY=./results
# OUTPUT_INCLUDE_METADATA=true
# OUTPUT_MAX_CONCURRENT_JOBS=5

# ----------------------------------------------------------------------------
# Path Configuration
# ----------------------------------------------------------------------------
# UPLOADS_DIR=/home/appuser/app/uploads
# PROMPTS_DIR=/home/appuser/app/prompts
# INPUT_DIR=/home/appuser/app/input
# OUTPUT_DIR=/home/appuser/app/output

# ----------------------------------------------------------------------------
# API Configuration
# ----------------------------------------------------------------------------
API_PORT=8000
# API_HOST=0.0.0.0
# API_RATE_LIMIT=9999

# API Authentication
# API_AUTH_ENABLED=false
# API_KEY=your_secret_api_key

# API Timeouts
# API_TIMEOUT_CONNECT=30
# API_TIMEOUT_READ=null

# CLI API Base URL (for local testing)
# FILEINTEL_API_BASE_URL=http://localhost:8000/api/v2

# ----------------------------------------------------------------------------
# Celery Configuration
# ----------------------------------------------------------------------------
# CELERY_TASK_SOFT_TIME_LIMIT=null
# CELERY_TASK_TIME_LIMIT=null
# CELERY_WORKER_POOL_RESTARTS=true
# CELERY_WORKER_POOL_RESTART_TIMEOUT=120
# CELERY_WORKER_MAX_TASKS_PER_CHILD=100

# ----------------------------------------------------------------------------
# CLI Configuration
# ----------------------------------------------------------------------------
# CLI_TASK_WAIT_TIMEOUT=null

# ----------------------------------------------------------------------------
# Batch Processing Configuration
# ----------------------------------------------------------------------------
# BATCH_DEFAULT_FORMAT=json
# BATCH_MAX_UPLOAD_SIZE=50
# BATCH_MAX_FILE_SIZE_MB=100
# BATCH_MAX_PROCESSING_SIZE=20
